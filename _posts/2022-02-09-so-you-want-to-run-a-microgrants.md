---
title: "So You Want To Run A Microgrants Program"
subtitle: "..."
date: 2022-02-09
author: Scott Alexander
comments: https://www.astralcodexten.com/api/v1/post/47831268/comments?&all_comments=true
image: https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/85cb0cbd-d87c-4265-aa58-9f795e5f913e_1388x896.jpeg
original-url: https://www.astralcodexten.com/p/so-you-want-to-run-a-microgrants
---
**I.**

Medical training is a wild ride. You do four years of undergrad in some bio subject, ace your MCATs, think you’re pretty hot stuff. Then you do your med school preclinicals, study umpteen hours a day, ace your shelf exams, and it seems like you're pretty much there. Then you start your clinical rotations, get a real patient in front of you, and you realize - oh god, I know absolutely nothing about medicine.

This is also how I felt about [running a grants program](https://astralcodexten.substack.com/p/apply-for-an-acx-grant).

I support effective altruism, a vast worldwide movement focused on trying to pick good charities. Sometimes I go to their conferences, where they give lectures about how to pick good charities. Or I read their online forum, where people write posts about how to pick good charities. I've been to effective altruist meetups, where we all come together and talk about good charity picking. So I felt like, maybe, I don't know, I probably knew some stuff about how to pick good charities.

And then I solicited grant proposals, and I got stuff like this:

**A.** $60K to run simulations checking if some chemicals were promising antibiotics.   
**B.** $60K for a professor to study the factors influencing cross-cultural gender norms  
**C.** $50K to put climate-related measures on the ballot in a bunch of states.  
**D.** $30K to research a solution for African Swine Fever and pitch it to Uganda  
**E.** $40K to replicate psych studies and improve incentives in social science

Which of these is the most important?

Part of my brain keeps helpfully suggesting "Just calculate how much expected utility people get from each!" I can check how many people die of antibiotic-resistant infections each year (Google says either 30K, 500K, or 1M, depending on which source you trust). That's a start! But the chance of these simulations discovering a new antibiotic is - 10%? 1%? 0.00001%? In silico drug discovery never works and anyone with half a brain knows that? The compounds being tested are dumb compounds? Even if they worked, bacteria would just develop more resistance in a week? Pharma companies would capture all the value from any new antibiotics and make it impossible for poor people to afford them? Five much better labs have already tried this and all the low-hanging fruit has been picked? Screening for new antibiotics is a great idea but actually it costs $4.50 and this is outrageously overpriced?

And that's an easy one. What about B? If the professor figures out important things about what influences gender norms, maybe we can subtly put our finger on the scale. Maybe twenty years later, women across the Third World will have equal rights, economic development will be supercharged, and Saudi Arabia will be a Scandinavian-style democracy with a female Prime Minister. But maybe the professor won't find anything interesting. Or maybe they _will_ find something interesting, but it will all be stuff like "it depends what kind of rice they cultivated in 4000 BC" and there won't be any subtle finger-putting-on-scale opportunities. Or maybe the professor will find something great, but nobody will listen to her and nothing will happen. Or maybe Third World countries will get angry at our meddling and hold coups and become even more regressive. Or maybe we'll overshoot, and Saudi Arabia will become really woke, and we'll have to listen to terrible takes about how the Houthi rebels are the new face of nice guy incel misogyny.

Which is higher-value, A or B? Probably more women suffer under oppressive gender norms than people die of antibiotic-resistant infections, but dying is probably worse than inequality, and there's a clearer path from antibiotic -> recovery than from research paper -> oppressive countries clean up their act. What about second order effects? If women have more equality in Saudi Arabia, maybe an otherwise unrecognized female genius will discover a new antibiotic. But if we have more antibiotics, someone who would otherwise have died of a bacterial infection might liberate women in Saudi Arabia. Aaagh!

Part of my brain helpfully suggests "Do a deep dive and answer these questions! This is the skill you are supposedly good at!" Quantifying these questions sounds crazy, but I am nothing if not [crazy for quantifying things](https://slatestarcodex.com/2013/05/02/if-its-worth-doing-its-worth-doing-with-made-up-statistics/). It could work.

…except that I had 656 applications like this, and everyone told me it was important to get back to people within a month or two. I don't think I could fully explore the subtleties of the antibiotic proposal in that time - let alone 656 proposals, most of which were even less straightforward.

**II.**

There’s a well-known solution to this kind of thing:

Just make a ballpark guess and then get on with your life.

The problem is: this grants program could be the most important thing I’ll ever do. Maybe everything else, all my triumphs and failures, will end up less important than getting this one grants program right.

GiveWell estimates that if you donate to their top charity, Against Malaria Foundation, you can probably save a life [for about $5000](https://www.givewell.org/cost-to-save-a-life). ACX Grants raised $1.5 million. Donated to AMF, that’s enough to save 300 lives. I didn’t donate it to AMF. I believed that small-batch artisanal grant-making could potentially outperform the best well-known megacharities - or at least that it was positive value in expectation to see if that was true. But if your thesis is “Instead of saving 300 lives, which I could totally do right now, I’m gonna do this other thing, because if I do a good job it’ll save _even more_ than 300 lives”, then man, you had _really_ better do a good job with the other thing.

Robin Dunbar [claims](https://en.wikipedia.org/wiki/Dunbar%27s_number) that humans have a capacity to handle 150 social relationships. Count up my friends, family members, coworkers, and acquaintances, and there will probably be about 150 who I can remember consistently and have some vague emotional connection to. If I made some mistake that killed all those people - all my friends, relatives, everyone I know - then in some “objective” sense, that would be about as bad as screwing up this grants program in some way that made it only half as good as the malaria counterfactual.

This isn’t what really bothers me. My brain refuses to believe it, so I don’t really care. The part that really bothers me is that I know a lot of middle-class people who are struggling. Somebody who’s $10,000 in credit card debt, and it’s making their life miserable. Someone else who posts a GoFundMe for a $5,000 medical bill. Another person who’s burned out at their $40,000 a year job and would probably have vastly better health if they could take a few months off and then job-search from a place of financial stability. 

If on average these people need $10,000 each, my $1.5 million could help 150 of them. Most of these wouldn’t literally save lives, but a few might - I [saw a patient once](https://slatestarcodex.com/2015/02/12/money-money-everywhere-but-not-a-cent-to-spend/) who attempted suicide for want of $5,000. And it would sure brighten a lot of people’s years.

So: $60,000 could test some promising antibiotics, or fund a book on gender norms. But it could also cure twelve Africans who would otherwise die of malaria, or save 5-10 Americans struggling under dead-end jobs and unpayable debts.

I tried not to think too hard about this kind of thing; I’m nervous it would make me so crazy that I’d run away from doing any kind of charity at all, and then everyone would be worse off. Even more, I’m worried it would scare me into taking only the most mainstream and best-established opportunities, whereas I really do think a lot of value is in weird charity entrepreneurship ideas that are hard to quantify.

But I couldn’t push it out of my mind far enough to do a half-assed job on the grants round, which meant confronting some of those problems head-on.

**III.**

…by which I mean “passing them off to other people”.

All those effective altruism conferences might not have given me infallible grant-making heuristics, but they did mean I knew a lot of grantmakers. I begged the institutional EA movement for help, and they lent me experts in global poverty, animal welfare, and the long-term future. I was able to draw on some other networks for experts in prediction markets and meta-science.

There wasn't as ready-made an EA infrastructure for biology, so I jury-rigged a Biology Grants Committee out of an ex-girlfriend who works in biotech, two of her friends, a guy who has good bio takes in the ACX comments section, and a cool girl I met at a party once who talked my ear off about bio research. Despite my desperation, I lucked out here. One of my ex’s friends turned out to be a semiprofessional bio grantmaker. The guy from the comments section was a bio grad student at Harvard. And the girl from the party got back to me with a bunch of detailed comments like “here’s the obscure immune cell which will cause a side effect these people aren’t expecting” or “a little-known laboratory in Kazakhstan has already investigated this problem”.

These people really came through. Don’t take my word for it - trust the data. The five of their opinions correlated with each other at r = 0.55, whereas my uninformed guesses only correlated with them at r = 0.15. This made me feel much more confident I was picking up something real. 

But even the “experts” weren’t perfectly aligned. There were three proposals where one evaluator assigned the highest possible rating, and another assigned the lowest possible. Sometimes these were differences of scientific opinion. Other times they were more fundamental. One person would say "This idea would let you do so many cool things with viruses" and another person would say "This idea would let you do so many cool things with viruses, such as bioterrorism".

Still, with their help I started to feel like I was finally on top of this.

**IV.**

Then I got the rug pulled out from under my feet again.

I was chatting online with my friend Misha about one the projects my Bio Grants Committee had recommended. He asked: given that they got funding from XYZ incubator a few years ago, why are they asking you for more funding now? XYZ incubator is known for funding their teams well, so they must have lost faith in these people. Some reports from a few years ago included the name of an impressive guy on their executive team, but more recent reports don’t mention him. The simplest explanation is that something went wrong, their executives expected rough going, their incubator got cold feet, and now they’re turning to a rube like you to help them pick up the pieces.

I was kind of flabbergasted. I had a very nice report from my Bio Committee telling me that all the science here was sound, the cells they were working with were very nice cells, etc. But here was a whole new dimension I hadn’t considered. Misha explained that he was an angel investor - not even some kind of super-serious VC, just a guy who invested his own money - and this kind of thing was standard practice in his field.

I’ll be honest. I know a lot of you are VCs. You read and support my blog, and I appreciate it. Some of the grant money I distributed came from VCs, which was very generous. But I always imagined you guys as kind of, you know, wandering into work, sipping some wine, saying “Hmmm, these guys have a crypto company, crypto seems big this year, I like the cut of their jib, make it so,” and then going home early. I owe you an apology. VC-ing is a field as intense and complicated and full of pitfalls as medicine or statistics or anything else.

As a grant-maker, I was basically trying to be a VC, only without the profit motive. But that meant I was staking $1.5 million on my ability to practice a very difficult field which, until five minutes previous, I hadn’t realized existed.

I solved this problem the same way I had solved my previous few problems: I begged Misha for help, and he agreed to serve on my grant evaluation team. But this kind of thing kept happening. Every time I thought I knew approximately how many different variables I needed to consider, my ship accidentally got blown off course into an entire undiscovered new continent of variable-considering, full of golden temples and angry cannibals.

I’m not going to write up the whole travelogue, but here are ten things worth thinking about if you’re considering a grants program of your own:

_(1): Many applicants ask for a random amount of money, and it’s your job to decide if you should give more or less._

For example, I originally said my grants would max out at 50-100K, and many people asked for 50-100K grants. Some of these people needed more than 50-100K, but figured any little bit helped. Others needed less than 50-100K, but figured they’d ask for more and let me bargain them down. Others had projects that scaled almost linearly, such that 50K could do ten times as much good as 5K, but only a tenth as much as 500K. They asked for 50-100K too.

Suppose I gave a dozen organizations $50K. It would be _really suspicious_ if a dozen organizations just happened to all be equally effective at spending the marginal dollar! The people screening new antibiotics and the people untangling cross-cultural gender roles really have _exactly equal_ expected value? Realistically it shouldn’t be at all surprising if one of them was ten or a hundred times more valuable than the other! So maybe instead of giving both of them $50K, I should give one of them $100K and the other one nothing. 

There was a strong temptation for me to make lots of different grants, because then I would feel like a good person who’s helped many different causes. In many cases, I succumbed to this temptation: realistically I don’t know which of those two causes is better, and realistically I don’t know enough about how each of them scales with money to second-guess the grant-writers who requested approximately $50K each. 

But also, after making all my other choices, I nixed the five or six least promising grants, the ones I secretly knew I had only done to feel like a diverse person who gives to diverse cause areas, and gave all their money to the oxfendazole project, which most evaluators agreed was the most promising.

_(2) Most people are terrible, terrible, TERRIBLE grantwriters_

It’s fascinating! They’re all terrible in different ways!

One person’s application was the very long meandering story of how they had the idea - “so i was walking down the street one day, and I thought…” - followed by all the people they had gone to for funding before me, and how each person had betrayed them.

Another person’s application sounded like a Dilbert gag about meaningless corporate babble. “We will leverage synergies to revolutionize the paradigm of communication for justice” - paragraphs and paragraphs of this without the slightest explanation of what they would actually do. Everyone involved had PhDs, and they’d gotten millions of dollars from a government agency, so maybe I’m the one who’s wrong here, but I read it to some friends deadpan, it made them laugh hysterically, and sometimes they still quote it back at me - “are you sure we shouldn’t be leveraging synergies to revolutionize our paradigm first?” - and _I_ laugh hysterically.

Several applications were infuriatingly vague, like “a network to encourage talented people”. I, too, think talented people should be encouraged. But instead of answering the followup questions - how do you find the talented people? why would they join your network? what will the network do to encourage them? - the application would just dribble out a few more paragraphs about how under-encouraged the talent was these days.

A typical pattern was for someone to spend almost their entire allotted space explaining why an obviously bad thing was bad, and then two or three sentences discussing why their solution might work. EG five paragraphs explaining why depression was a very serious disease, then a sentence or two saying they were thinking of fighting it with some kind of web app or something.

Several applications very gradually made it clear that they had not yet founded the charitable organization they were talking about, they had no intention of doing so, and they just wanted to tell me they thought _I_ should found it, or somehow expected my money to cause the organization to exist.

This proved to be a sort of skeleton key to diagnose a whole genus of grant-writing pathologies: I think some people don’t understand, on a deep level, that between the steps “people donate money to cause” and “cause succeeds”, there’s an additional step of “someone takes the money and does some specific thing with it”. Or they thought it could be abstracted away - surely you just hire some generic manager type. Yeah, these grant applications are auditions for that job, and you failed.

One person, in the process of explaining why he needed a grant, sort of vaguely confessed to a pretty serious crime. I don’t have enough specifics that I feel like I can alert police, and it’s in a different country where I don’t speak the language. Still, this is a deeper grantwriting failure than I imagined possible.

_(3): Your money funges against the money of all the other grants programs your applicants are applying to._

Right now AI alignment has _lots_ of cash. If there’s a really good AI alignment charity, Open Philanthropy Project and Founders Fund and Elon Musk and Jaan Tallinn will all fight each other to throw money at it. So if a seemingly really good AI alignment charity asked me for money, I would wonder - why haven’t they gotten money from a big experienced foundation? 

Maybe they asked and the big experienced foundations said no - but then, do I think I’m in a position to second-guess the experts? Or maybe they don’t know the big experienced foundations exist, which suggests they’re pretty new here - not necessarily a fatal flaw, but something to think about. Or maybe they’re asking the big experienced foundations too, but they figured they’d use me as a backup.

How is this actionable? First, sometimes I was able to ask the big experienced foundations if they’d seen a grant application, and if so what they thought. But second, if I had a great global poverty proposal and a great AI safety proposal, and I thought they were both equally valuable, the correct course was to fund global poverty and ask the Long Term Future Fund to fund the AI safety one.

(what actually happened was that the Long Term Future Fund approached _me_ and said “we will fund every single good AI-related proposal you get, just hand them to us, you don’t have to worry about it”. Then I had another person say “hand me the ones Long Term Future Fund doesn’t want, and I’ll fund those.” Have I mentioned it’s a good time to start AI related charities?)

Sometimes an experienced grantmaker would tell me that some specific application would be catnip for the XYZ Foundation, and we could forward it on to them instead of funding it ourselves. This made me nervous, because what if they were wrong and this great proposal slipped through the cracks? - but usually I trusted them.

_(4) There are lots of second-order effects, but you’ll go crazy if you think about them too hard_

Suppose a really good artist comes to you and asks for a grant. You think: “Art doesn’t save too many lives. But this art would be really good, and get really famous, and then _my grants program_ would get really famous for funding such a great thing, and then lots more funders and applicants would participate the next time around.”

Or suppose some promising young college kid asks you for a grant to pursue their cool project. Realistically the project won’t accomplish much, but she’ll learn a lot from it. And she seems like the sort of person who could be really impressive when she gets older. Is it worth giving her a token amount to “encourage her”? (my impression is that Tyler Cowen would say “Hell yes!” and that this is central to his philosophy of grantmaking). What about buying the right to boast “I was the first person to spot this young talent!” thirty years later when she wins her Nobel, which brings glory to your grants program down the line? What about buying her goodwill, so that when she’s head of the NSF one day you can ask a favor of her? Doesn’t that promote your values better than just giving money to some cool project?

(but remember that $10K = saving two Africans from malaria, or relieving one American’s crushing credit card debt. That’s quite a price to “encourage young talent”, isn’t it?)

What if there’s a project you don’t think will succeed, but which is _very close_ to a field you want to encourage? Do you fund it in order to build the field or lure other people in? What about a project you _do_ think will do good, but which is very close to something bad? 

The experienced grantmakers I worked with mostly suggesting weighing these kinds of considerations less. They take too much precise foreknowledge (this art will become famous, this young student will become an impressive luminary, my grants will move lots of people into this field) when realistically you don’t even have enough foreknowledge to predict if your grant will work at all.

Still, Tyler Cowen does this and it works for him. My only recommendation is to make a decision and stick to it, instead of going crazy thinking too hard.

_(5) Being advised by George Church is not as impressive as it sounds_

One applicant mentioned that his bio project was advised by George Church - Harvard professor, National Academy of Sciences member, one of TIME Magazine’s “100 Most Influential People In The World”, and generally amazing guy. I was astonished that a project with Church’s endorsement was pitching to me, and not to Peter Thiel or Elon Musk or someone.

Then I got another Church-advised project. And another.

What finally cleared up the mystery is that one of my Biology Grants Evaluation Committee members _also_ worked for George Church, and clarified that Church has seven zillion grad students, and is extremely nice, and is bad at saying no to people, and so half the biology startups in the world are advised by him. There are lots of things like this. [Remember](https://en.wikipedia.org/wiki/Goodhart%27s_law): when a measure becomes a target, it ceases to be a good measure!

_(6): Everyone is secretly relying on everyone else to do the hard work._

Sometimes people gave me pitches like “[Fintech billionaire] Patrick Collison gave us our first $X, but he didn’t fund us fully because he wanted to diversify our income streams and demonstrate wider appeal. Can you fill the rest of our funding for the year?” This was a pretty great pitch, because Patrick is very smart, has a top-notch grant-making infrastructure, and shares many of my values. I was pretty desperate to be able to rely on something other than my wits alone, and Patrick’s seal of approval was a tempting proxy. I tried to give all these people a fair independent evaluation, because otherwise it would defeat the point of Patrick making them seek alternative funding sources. But it sure did get them to the top of the pile.

Then people started sending _me_ requests like “Please give us whatever you can spare, just so that when we’re pitching to some other much richer person, we can say that other grantmakers such as yourself are on board.” This made me really nervous. It was bad enough risking my own money (and the money of my generous donors). But risking my reputation was something else entirely. If all grantmakers secretly relied on other grantmakers to avoid the impossibly complex question of figuring out who was good, then my decisions might accidentally move orders of magnitude more money than I expected. It’s all nice and well to replace your own judgment with Patrick Collison’s. But what if someone tried to replace their own judgment with _mine_?

I have no solution here except to type up this 5000 word essay on how I really don’t know what I’m doing and you shouldn’t trust me. Those who have ears to hear, let them listen!

_(7) If you can’t rely on other grantmakers, you’ll rely on credentials_

I still think that credentialism - the thing where you ignore all objective applications of a person’s worth in favor of what college they went to - is bad. But now I understand why it’s so tempting.

I’d previously been imagining - you’re some kind of Randian tycoon, sitting serenely in your office, reviewing resumes for your 1001st software engineering drone. You can easily check how they do on various coding exams, Project Euler, peer ratings, whatever, but instead you go with the one who went to Harvard, because you’re a f@#$ing elitist.

Now I’m imagining - you’re a startup founder or mid-level hiring manager or something, getting thrown into the deep end, asked to make a hire for your company despite having no idea what you’re doing. If you get it wrong, the company’s new product will flop and everyone will blame you. One software engineer claims to be an expert in non-Euclidean para-computing, whatever that is, and the other claims to be an expert in ultravectorized peta-fragmentation, or something to that effect. You Google both those terms and find that StackOverflow has removed the only question about them because it’s “off-topic”. The Standardized Coding Exam That Everyone Has Taken Which Allows Objective Comparison turns out not to exist. Project Euler exists, but you worry if you asked them about it they would think you’re crazy and obsessive. So you go with the one who has a Computer Science degree from Harvard, because at least he’s probably not literally lying about the fact that he knows what a computer is.

(it’s not that everyone is an imposter with no idea what they’re doing. But everyone _starts out that way_ , and develops their habits when they’re in that position, and then those habits stick.)

_(8) You will suffer heartbreak_

I’d been on a couple of dates with someone a month or two before the grants program. Then in the chaos of sorting through applications, I forgot to follow up.

Halfway through the grant pile, I found an application from my date. It was pretty good, but I felt like it would be too much of a conflict of interest. I sent them an email: “Sorry, I don’t feel like I can evaluate this since we’re dating”.

The email back: “I don’t consider us to still be dating”. This remains the most stone-cold rejection I have ever gotten.

_(9) If you can’t rely on other grantmakers or credentials, you’ll rely on prejudices and heuristics_

Here are some of mine: your new social network won’t kill Facebook. Your new knowledge database won’t kill Wikipedia. No one will ever use argument-mapping software. No matter how much funding your clever and beautiful project to enforce truth in media gets, the media can just keep being untruthful. The more requests for secrecy are in a proposal, the less likely it is to contain anything worth stealing. Subtract one point for each use of the words “blockchain”, “ML”, and “BIPOC”.

A lot of these italicized sections here are trying to get at the same point: when you’re truly lost in a giant multidimensional space that requires ten forms of expertise at once to make real progress, you’ll retreat to prejudices and heuristics. That’s what credentialism is, that’s what relying on other grantmakers is, and - when you have neither Harvard nor Patrick Collison to save you, you’ll rely on [that one blog post you read that one time saying X never works](https://markusstrasser.org/extracting-knowledge-from-literature/).

_(10) …but your comparative advantage might be in not doing any of this stuff_

See my post from yesterday, [Heuristics That Almost Always Work](https://astralcodexten.substack.com/p/heuristics-that-almost-always-work).

What’s your story for why you need a microgrants program? Why not just donate to GiveWell or OpenPhil or some other charity or foundation you respect?

(technically OpenPhil doesn’t accept individual donations, but if you break into their office and leave $1.5 million on a desk, what are they going to do?)

If your story is “I have a comparative advantage in soliciting grant proposals” or “I have a comparative advantage in soliciting funders” or even “it takes the excitement of a personal grants program to incentivize me to do charity at all”, then fine, whatever.

But if your story is “I think I have a comparative advantage in assessing grants” - then consider actually having a comparative advantage in assessing grants.

If you only fund teams with a lot of Harvard PhDs who already have Patrick Collison’s seal of approval, you don’t have much of a comparative advantage. You could be replaced by a rock saying “FUND PRESTIGIOUS PEOPLE WHO OTHER PRESTIGIOUS PEOPLE LIKE”. I don’t want to say they’re _sure_ to get funding - one of life’s great mysteries is how many foundations are desperate for great causes to fund, how many great causes are desperate for funding, and how the market still doesn’t always clear. And if everyone galaxy-brains themselves into not funding the obvious best teams, then the obvious best teams never get funded. And the surest way not to do that is to stop galaxy-braining and fund the obvious best teams.

Still, given that your money is somewhat fungible with other people’s money, one way to have an outsized impact is to outperform that rock. That means trying to find undervalued projects. Which means not _just_ using the same indicators of value as everyone else: credentials, popular cause areas, endorsements. It means taking chances, trying to cultivate long-term talent, trying to spot the opportunities you’re uniquely placed to see and other people are most likely to miss.

This is a dangerous game - most of the time you try to beat Heuristics That Almost Always Work, you fail. Still, part of what you’re doing in setting yourself up as a grants evaluator is claiming to be able to do this (unless you have another story in mind, like that you’re good at soliciting proposals or leveraging your personal brand to get funding). The overall grantmaking ecosystem needs some people to take the obvious high-value opportunities, and other people to seek out the opportunities whose value isn’t obvious. If you want to be the latter, good luck.

The other way the HTAAW post is relevant here: beware of information cascades. If you give someone a grant because they have good credentials and two other grantmakers approved of them, they’re going to be telling the next guy “We have good credentials and _three_ other grantmakers approve of us!” This was another worry that pushed me to put a supra-HTAAW level of work into some grants.

**V.**

If you solve all these problems, congratulations! You can write a blog post announcing that you are giving out grants! People you respect will say nice things about you and be happy!

[![Twitter avatar for @Meaningness](https://substackcdn.com/image/twitter_name/w_96/Meaningness.jpg)David Chapman @MeaningnessAmazing and wonderful! @slatestarcodex’s small grants program awards. Many/most of these seem both worthy and unlikely to get funding through established means. Hopepunk in the real world :) ](https://twitter.com/Meaningness/status/1475984501398335491)[![](https://substackcdn.com/image/fetch/w_600,h_314,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F50475988-7554-494a-a3c9-7a7851d0eb0f_964x675.jpeg)astralcodexten.substack.comACX Grants Results...](https://astralcodexten.substack.com/p/acx-grants-results)[12:18 AM ∙ Dec 29, 2021

* * *

90Likes10Retweets](https://twitter.com/Meaningness/status/1475984501398335491)

[![Twitter avatar for @srajagopalan](https://substackcdn.com/image/twitter_name/w_96/srajagopalan.jpg)Shruti Rajagopalan @srajagopalanACX ⁦@slatestarcodex⁩’s EV-style grant looks fantastic. A very diverse group. Congrats to all the winners. More about the grant and winners here. ](https://twitter.com/srajagopalan/status/1476031038518439936)[![](https://substackcdn.com/image/fetch/w_600,h_314,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F66cd5371-eb2f-49e2-97f9-798e63574631_964x675.jpeg)astralcodexten.substack.comACX Grants Results...](https://astralcodexten.substack.com/p/acx-grants-results)[3:23 AM ∙ Dec 29, 2021

* * *

32Likes2Retweets](https://twitter.com/srajagopalan/status/1476031038518439936)

Then you have to actually give people money.

You know how, whenever there’s a debate about cryptocurrency, some crypto fanboy gushes about how it makes sending money so much easier? And if you’re like me, you think “yes, but right now you can just enter a number into Paypal, that already seems pretty easy to me”?

I take it all back. The crypto future can’t come soon enough. Sending money is terrible.

Paypal charges 2-3% fees. If you’re sending $50K, that’s a thousand dollars. Your bank might do wire transfers for you, but they have caps on how much you can send, and that cap may be smaller than your grant. Wires can involve anything from sending in a snail mail form, to going to the bank in person, to getting something called a “Medallion Signature Guarantee” which I still have not fully figured out. Sometimes a recipient would tell me their bank account details, and my bank would say “no, that account does not exist”, and then we would be at an impasse. If you have double (or God forbid, triple) digit numbers of recipients, it all adds up.

I solved this the same way I solved everything else - begged friends and connections to do it for me. The Center For Effective Altruism agreed to take over this part, which was a lifesaver but created its own set of headaches. They’re a tax-deductible registered charity, which means they’re not supposed to give money to politics or unworthy causes. But some of my recipients were doing activism or things that were hard to explain to the federal government (eg helping a researcher take some time off to re-evaluate their career trajectory). They asked me to handle those myself, and I muddled through. Also, registered charity aren’t allowed to let donors influence its grant-making decisions, so I wasn’t allowed to donate directly to my own grants program; I had to split it in two and fund my fraction separately, with inconsistent tax-deductibility. 

I understand that Molly Mielke is working on a project called [Moth Minds](https://www.mothminds.com/) that will take away the headache and make personal grants programs easier. So far her website is heavy on moth metaphors and light on details, but moth metaphors are also good, and I’m long-term excited about this.

**VI.**

More and more people are talking about microgrants programs. Maybe you’re one of them. So: should you run a grants round?

Your alternative to running a grants round is giving to the best big charities that accept individual donations. GiveWell tries to identify these, and ends up with things like Against Malaria Foundation, which they think can save a life for ~$5,000. So to a first approximation, run a grants round if you think you can do better than this.

Why should you expect to do better than these smart people who have put lots of effort into finding the best things? GiveWell mostly looks at scale-able and stable projects, but most microgrants work with small teams of people pursuing idiosyncratic opportunities. Funding research teams, activist groups, and companies/institutions can easily outperform direct giving to individuals.

There _are_ very large organizations who handle these kinds of one-off grants. They’re _also_ smart people who put lots of effort into finding the best things. So why should you expect to outperform _them_?

Maybe because they say you can. I talked to some of these big foundation people, and they were unexpectedly bullish on microgrants. They feel like their organizations are more limited by good opportunities than by money. If you can either donate your money or your finding-good-opportunities ability, consider the latter.

How can big foundations be short of good opportunities when the world is so full of problems? This remains kind of mysterious to me, but my best guess is that they set some high bar, donate to everything above the bar, and keep the rest of their money in the hopes that good charities that exceed the bar spring up later - or spend the money trying to create charities that will one day exceed the bar. Global health charities [sometimes set ](https://forum.effectivealtruism.org/posts/nXL2MeQQBoHknpz8X/what-s-the-role-of-donations-now-that-the-ea-movement-is?commentId=vCeGqpbd9HQseGsSt)a bar of “10x more effective than GiveDirectly”, where GiveDirectly is a charity that gives your money directly to poor people in Africa; other cause areas are harder to find a bar for but maybe you can [sort of eyeball it](https://forum.effectivealtruism.org/posts/nXL2MeQQBoHknpz8X/what-s-the-role-of-donations-now-that-the-ea-movement-is?commentId=vCeGqpbd9HQseGsSt). This model suggests you should only donate your finding-good-opportunities ability if you think there’s a chance you can clear the relevant bar, but there might be pretty high value of information in seeing whether this is true.

Anyone deeply interested in this question should read Carl Shulman’s [Risk-neutral donors should plan to make bets at the margin at least as well as giga-donors in expectation](https://forum.effectivealtruism.org/posts/BhvTMY7K7z97tbHgS/risk-neutral-donors-should-plan-to-make-bets-at-the-margin) and Benjamin Todd’s comment [here](https://forum.effectivealtruism.org/posts/nXL2MeQQBoHknpz8X/what-s-the-role-of-donations-now-that-the-ea-movement-is?commentId=vCeGqpbd9HQseGsSt). But here are some preliminary reasons why your microgrants program might be worth it:

_Because you have a comparative advantage in soliciting proposals_. Big effective-altruist foundations complain that they’re entrepreneurship-constrained. That is, funders give them lots of money, they’ve already funded most of the charities they think are good up to the level those charities can easily absorb, and now they’re waiting for new people to start new good charities so they can fund those too. This is truest in AI alignment, second-truest in animal welfare and meta-science, and least true in global development (where there are always more poor people who need money). ACX Grants got some people who otherwise wouldn’t have connected with the system to get out there and start projects, or at least to mention that their project existed somewhere that people could hear it. One of my big hopes is that next year or the year after OpenPhil gives $10 million or something to some charity they learned about because of me. I don’t know if this will happen but I think the possibility made this grants round worthwhile in expectation.

_Because you have a comparative advantage in getting funding_. I might have been in this category: I think some people trusted me with their money who wouldn’t necessarily have trusted OpenPhil or GiveWell. But I’m having trouble thinking of many other scenarios where this would happen.

_Because you have a comparative advantage in evaluating grants._ This one is tough. The big foundations have professional analysts and grantmakers. These people are really smart and really experienced. Why do you think you can beat them at their own game?

One possible answer: you’re also really smart and experienced. Fast Grants is run by Tyler Cowen and Patrick Collison (plus Emergent Ventures with Shruti Rajagopalan); it wouldn’t surprise me if their particular genius is more valuable than a big foundation’s increased specialization and resources. If that’s you, then good work, I guess.

A second possible answer: no big foundation exactly captures your beliefs and values. Scott Aaronson [ran a grants round recently](https://scottaaronson.blog/?p=6256) and donated entirely to causes involved in STEM education. Maybe he thinks STEM education is more important than other big players believe (which actually seems very plausible). Or maybe his value system puts less emphasis on pleasure vs. suffering compared to the human urge toward deep understanding of Nature, and he feels incompletely aligned with OpenPhil who eg [donate $786,830 to crustacean welfare](https://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare/crustacean-compassion-general-support).

A third possible answer: you have no absolute advantage, but you do have a comparative advantage. Scott Aaronson was both a student and professor at one of the math education groups he donated to, knew people who had been to the others, and had readers of his (math-focused) blog advise him on others still. I totally believe Aaronson is at least as qualified to evaluate math education as big foundations are, especially math-education-as-understood-and-appreciated-by-Scott-Aaronson’s-values. I gave several grants to prediction markets, something I’m plausibly an expert on. 

(which is a bad example, because the small handful of people who know more about prediction markets than I do are disproportionately employed as OpenPhil grantmakers. But _one day_ I’ll find a cool new field before OpenPhil does, and then I’ll give it lots of grants and feel very smug.)

So, all of these are ways your microgrants can potentially add value over a generic gift to someone else. So why might you _not_ want to start your own grants program?

Sometimes human temptations caught up with me. I funded some grants that were cool, and made me seem cool for funding them, and made me happy, and supported my politics and identity commitments - but which, when I judge them by the standards of “was giving these people $X better than saving $X/5000 lives from malaria or relieving $X/10,000 people’s life-ruining credit card debts?”, probably fail. Part of the appeal of GiveWell is that you don’t have to win any spiritual battles against temptation; you know you’re doing _more or less_ the right thing. Grants programs throw you right into the middle of spiritual battles, each one you lose counts against your effectiveness rate, and after you lose enough you’re subtracting value instead of adding it.

So should you run your own grants program, or donate to an existing charity?

If you have any of the above comparative advantages, if you plan to work hard enough to realize them, and if you win spiritual battles so consistently that you have to fight off recruiters for your local paladin order - I say try the program.

If not - and especially if you expect to half-ass the evaluation process, or succumb to the pressure to give to feel-good causes that aren’t really effective - then donate to existing charities. I really don’t want to make this sound like the loser option: donating to existing charities is usually the right thing to do, and choosing the less flashy but more effective option is also a heroic act.

If you’re on the fence, I’d err on the side of doing it, since the upside is potentially very high and the downside limited.

**VII.**

There’s one other reason to run a microgrants program: you think it would be fun.

I have no moral objection to this. Nothing along the lines of “wouldn’t it be better to something something expected utility?” Realistically the highest expected utility thing is whatever gets you interested enough to donate. If that’s a grants program, do it.

My actual objection is: no it won’t be.

I can’t say this with certainty. Some people are very weird. Some people are masochists. Some people already have experience in a related field and won’t feel as overwhelmed as I did.

But I’m already scheming ways to try to capture the positive effects of a grants program without having to run one myself. If the American way is a “government of laws, and not of men”, then the ACX way is a government of byzantine highly speculative institutions instead of men. So I’m thinking about how to replace my role with a [impact certificate](https://forum.effectivealtruism.org/posts/yNn2o3kEhixZHkRga/certificates-of-impact)-based [retroactive public goods funding market](https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c), and working on talking to various interesting people who might be able to make this happen. Once I recover from the current grants round, I’ll push them harder and see if we can get a prototype by next fall.

The basic idea would be: you all send in your grant proposals as usual. I (and any other interested funders) pledge some amount of money (let’s say $250K) to be distributed to successful projects one year later, ie _after_ they’ve succeeded and made a difference. Then some group of savvy investors (or people who _think_ they’re savvy investors) commit the same amount of _their_ money (so $250K in our example) to buying grants, ie fully funding them in exchange for a meaningless certificate saying they “own” the grant - if people wanted, this could be an NFT, since that technology excels in producing meaningless certificates. At the end of some period, maybe a year, I would come in with my $250K and “give it” to the successful projects, by which I mean to whoever owned their impact certificates. Think of it as kind of like a prediction market for which grants will do well. Don’t worry, it’ll make more sense when we do it.

(don’t get too excited though, this will probably be harder than I expect, and maybe none of it will pan out)

All miserable slogs eventually become pleasant memories (eg high school, travel, medical residency). I can already sense the same thing happening to ACX Grants. I’m proud of what we accomplished, and with the pain fading away and only the fruits of our labor left, I feel like it was good work. 

But if you’re wondering whether or not to start a grants program, the most honest answer I can give is “I tried this once, and now I’m hoping to invent an entirely new type of philanthropic institution just to avoid doing it again.”
