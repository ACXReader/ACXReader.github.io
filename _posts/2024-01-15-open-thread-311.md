---
title: "Open Thread 311"
subtitle: "..."
date: 2024-01-15
author: Scott Alexander
comments: https://www.astralcodexten.com/api/v1/post/140692069/comments?&all_comments=true
image: https://substack-post-media.s3.amazonaws.com/public/images/027fb4d2-879e-4f43-9be2-09e1dde4f75b_251x255.png
original-url: https://www.astralcodexten.com/p/open-thread-311
---
This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial [subreddit](https://www.reddit.com/r/slatestarcodex/), [Discord](https://discord.gg/RTKtdut), and [bulletin board](https://www.datasecretslox.com/index.php), and [in-person meetups around the world](https://www.lesswrong.com/community?filters%5B0%5D=SSC). 95% of content is free, but for the remaining 5% you can subscribe **[here](https://astralcodexten.substack.com/subscribe?)**. Also:

**1:** Last week I posted [a subscribers-only book review of ](/p/book-review-cyropaedia)_[Cyropaedia](/p/book-review-cyropaedia)_. Several people commented that two days earlier, the Substack [Mr. and Mrs. Psmith’s Bookshelf](https://www.thepsmiths.com/) also [reviewed the same book](https://www.thepsmiths.com/p/review-the-education-of-cyrus-by) (the commenters politely omitted “and did a better job”). Highly recommended, whether you read my version or not.

**2:** Last year I bet that AI art generators would be able to handle some tough compositionality requests before 2025. There was widespread speculation that the latest generation (eg DALL-E2) had won this bet. Edwin Chen [has tested them out, and says they’re not quite there](https://twitter.com/echen/status/1744409535073165684).

**3:**[The PIBBSS Fellowship](https://pibbss.ai/fellowship/) asks me to remind you of their existence. They’re a 3-month fully-funded program in AI alignment. They take PhDs and postdocs from other fields "such as evolutionary bio, neuroscience, dynamical systems theory, economic/political/legal theory, and more" and help them work on a project "at the intersection of your own field and AI safety, under the mentorship of experienced AI alignment researchers". [Learn more / apply here](https://pibbss.ai/fellowship/) before the February 4 deadline. 
