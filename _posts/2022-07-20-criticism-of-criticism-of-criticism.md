---
title: "Criticism Of Criticism Of Criticism"
subtitle: "..."
date: 2022-07-20
author: Scott Alexander
comments: https://www.astralcodexten.com/api/v1/post/58139252/comments?&all_comments=true
image: https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/dbbee2ba-0507-48f7-914b-f6c78fe0df27_1024x1024.png
original-url: https://www.astralcodexten.com/p/criticism-of-criticism-of-criticism
---
**I.**

The voters wanted _[Anti-Politics Machine](https://astralcodexten.substack.com/p/your-book-review-the-anti-politics)_ to be a Book Review Contest Finalist this year, and I listened. But I wasn’t happy about it. I hate having to post criticism of EA.

Not because EA is bad at taking criticism. The opposite: they like it _too much_. It almost feels like a sex thing. “Please, tell me again how naughty I’m being!” I went to an EA organization’s offices once - I think it was OpenPhil, but don’t quote me on that - and the whole place was strewn with the most critical books you can imagine - Robert Reich, Anand Giradharadas, that kind of thing. Can’t remember seeing _Anti-Politics Machine_ but I’m sure it was there. Probably three copies per person. One for their office, one for their home library, and one for the spot under their mattress where other people would hide porn mags.

(I’m deliberately not expanding the acronym “EA”. If you don’t know what it is, think of it as a variable, like “X”. In fact, do this even if you _do_ know what it is.)

Many of the highest-upvoted posts on the EA Forum are criticism. The more critical, the more upvotes. A typical careful well-thought out post by a community leader gets 25, maybe 50 upvotes. A case against RCT-driven development aid, somewhat related to the one in _Anti-Politics Machine,_ got 389. It was the #6 highest upvoted post of all time; the only reason it wasn’t higher was because stronger criticisms of EA beat it out.

There are 147 posts tagged [criticism of EA](https://forum.effectivealtruism.org/topics/criticism-of-effective-altruism), 59 tagged [criticism of EA organizations](https://forum.effectivealtruism.org/topics/criticism-of-effective-altruist-organizations), 35 tagged, [criticism of the EA community](https://forum.effectivealtruism.org/topics/criticism-of-the-effective-altruism-community), and 66 tagged [criticism of EA culture](https://forum.effectivealtruism.org/topics/criticism-of-effective-altruist-causes) \- including 4 posts criticizing EA for being too unwilling to solicit and listen to criticism.

In the most EA thing to ever happen, some people have launched [a $100,000 prize for the best criticisms of EA](https://forum.effectivealtruism.org/posts/8hvmvrgcxJJ2pYR4X/announcing-a-contest-ea-criticism-and-red-teaming) (don’t bother writing in to criticize the contest, it’s already been done). At this point I think it would be cheaper to just hire professional dominatrices.

At this point, reading an article like this one, you already know what the next “narrative beat” has to be. Despite Their Superficial Openness To Criticism, People In EA Are Only Willing To Engage With A Narrow Selection Of Critiques That Flatter Their Preconceptions, While Truly Threatening Criticisms Are Excluded From The Window Of Acceptable Discourse. People Who Are Able To Speak The Language Of Power And Criticize EA Legibly In Its Own Terms Get Flattered And Rewarded With Trivial Changes, While People Who Genuinely Challenge The Establishment Are Dismissed As Beyond The Pale Of “Respectable” Criticism And Ignored Or Punished.

(while I was editing this essay, [someone wrote](https://forum.effectivealtruism.org/posts/qjMPATBLM5p4ABcEB/criticism-of-ea-criticism-contest) this inevitable thing, but I don’t think you should update too much on the details, any more than you would update on who in particular picked up a $20 bill on the ground, or what kind of bending motion they used)

The fact that this _has to_ be the next narrative beat in an article like this should raise red flags. Another way of phrasing “this _has to_ be the next narrative beat” is that it’s something we would believe / want to believe / insert at this place in our discourse whether it was true or not. That means we need to be on extra special good epistemic behavior when we try to consider whether it’s true in this individual case, understanding that we’ll have a strong bias towards assuming “yes” that needs to be counteracted.

Even more important, if the abstract egregore of EA has a humiliation fetish, that last paragraph - the one with “Despite Their Superficial Openness To Criticism, People In EA Are Only Willing To Engage With A Narrow Selection Of Critiques…” is at the _exact center_ of the fetish. That’s the one porn video that they keep coming back to, the one where they hope nobody opens their computer and notices the “You viewed this 5,946,728 times” caption in their browser history. 

This makes me suspicious.

**II.**

Psychiatry has its own stock criticisms of itself. We rely too much on pills. We don’t get to know patients enough as individuals. We only treat the symptoms, not the real disease of [insert wild speculation]. We are probably systemically racist somehow, details to be filled in later. Something something Thomas Insel’s RDoC program. Non-psychiatrists in the popular media have stolen these criticisms and made them dumber, but we had them all first.

In 2019 I reported on [the American Psychiatric Association’s annual meeting](https://slatestarcodex.com/2019/05/22/the-apa-meeting-a-photo-essay/). Here is a small fraction of the seminars on offer:

  * Disrupting The Status Quo: Addressing Racism In Medical Education And Residency Training

  * Grabbing The Third Rail: Race And Racism In Clinical Documentation

  * Treating Black Children And Families: What Are We Overlooking?

  * Revitalizing Psychiatry – And Our World – With A Social Lens

  * Gender Bias In Academic Psychiatry In The Era Of the #MeToo Movement

  * Making The Invisible Visible: Using Art To Explore Bias And Hierarchy In Medicine

  * Navigating Racism: Addressing The Pervasive Role Of Racial Bias In Mental Health

  * Racism And Psychiatry: Growing A Diverse Psychiatric Workforce And Developing Structurally Competent Psychiatric Providers

  * Sex, Drugs, And Culturally Responsive Treatment: Addressing Substance Use Disorders In The Context Of Sexual And Gender Diversity

  * Intersectionality 2.0: How The Film Moonlight Can Teach Us About Inclusion And Therapeutic Alliance In Minority LGBTQ Populations

  * Child Welfare – A System Psychiatrists Should Scrutinize

  * Inequity By Structural Design: Psychiatrists' Responsibility To Be Informed

Advocates For Systemic Education And Criminal Justice Reform

  * But I'm Not Racist: Racism, Implicit Bias, And The Practice Of Psychiatry




Disruption! Grabbing the third rail! Asking about what we’re overlooking! It seems that psychiatry, like EA, is really good at criticizing itself. Even better: these aren’t those soft within-the-system critiques everyone is worried about. These are hard challenges to the entire paradigm of capitalism or whatever.

And it’s not just the APA as an institution. Go to any psychiatrist at the conference and criticize psychiatry in these terms - “Don’t you think our field is systemically racist and sexist and fails to understand that the true problem is Capitalism?” and they will enthusiastically agree and maybe even tell you stories about how their own experience proves that’s true and how they need to try to do better.

Is there any criticism that can touch these people at all?

Here’s my proposal: ask [why they prescribe s-ketamine instead of racemic ketamine](https://slatestarcodex.com/2019/03/11/ketamine-now-by-prescription/) for treatment-resistant depression.

If you say this, psychiatrists will push back. If you say it in a confrontational way - maybe you hint that they’ve outsourced their thought processes to a handful of regulators and pharmaceutical companies even when this severely disadvantages patients, because thinking for themselves is hard and scary - they’ll get offended. The world is full of psychiatrists who will confess to systemic racism with a smile on their face, then get all huffy when you ask them about esketamine.

Here are other criticisms that I think can actually start fights: should tricyclics be higher on our treatment algorithm for depression than atypical antipsychotics? Should we use levothyroxine more (or less) often? And my nominee for “highest likelihood of people actually coming to blows” would be asking if they’re sure it’s ethical to charge poor patients three-digit fees for no-shows.

All of these are the opposite of the racism critique: they’re minor, finicky points entirely within the current paradigm that don’t challenge any foundational assumptions at all.

But you can actually start fights if you bring them up, instead of getting people to nod along and smile vacuously.

The racism critique doesn’t imply any specific person is doing any specific thing wrong. Certainly not you! It doesn’t demand any specific response except maybe more awareness, saying the right slogans, and _maybe_ having some other person form a committee to make meaningless changes to some set of bylaws. But the esketamine critique actually demands that you in particular go out and learn about a different medication which is kind of scary and could get you in trouble if you use it wrong. It implies that you personally are failing patients, in a way that some other doctors _aren’t_ failing patients. Maybe it means those other doctors are better than you! And so the knives come out.

**III.**

This is also how I think about EA criticism.

I’m going to give an example of criticism I don’t like. I hate doing this, because all the criticism pieces are heartfelt and people worked hard on them. But I have to pick on someone in particular, so I’m going to pick on [Some Blindspots In Rationality And Effective Altruism](https://forum.effectivealtruism.org/posts/LJwGdex4nn76iA8xy/some-blindspots-in-rationality-and-effective-altruism) (disclaimer: I appreciate the work that went into this and like the people involved). It tries to get ahead of any “this isn’t paradigm-busting enough” by making extremely general and abstract points, like:

  * EA assumes people are individuals, but actually, they are interdependent. Instead of swallowing western individualism, we need to be better at thinking within communalist and collectivist paradigms.

  * EA’s “views are built out of structures”. That is, we use semi-Aristotelian logical reasoning when in fact the world is a complicated inter-related whole. Traditional cultures “foster a process-based view” and we should also learn to think in those terms.

  * EAs seek impartiality and objectivity, but actually those things are illusions, and the observer is firmly planted within the world that he/she is observing.

  * We use dualist thinking, whereas many enlightened people have claimed that reality is non-dualist.




This is just a selection and I don’t claim I’m being fair or representative.

I’m having trouble expressing why I feel so uneasy about this. Part of it is emotional: I feel less enlightened than preached at. Do we _really_ not think of the interdependence between individuals? Does this _really_ make us less effective in some way? Or is this just a sort of stock criticism with such a storied tradition that everyone has agreed to nod their head to it and agree to do better later? Are we sure that becoming less individualist would be a better use of our energy than becoming _more_ individualist? How did we achieve that certainty? It sure seems like more individualist countries are richer and better places to live. And that within those countries, the most individualist regions and social networks are the richest and best. Aren’t more intelligent people generally more individualist when you do the psych tests and surveys? I don’t know, if I thought it was a good use of our resources to move some direction on the individualism spectrum, I would be kind of interested in trying to figure out how to move even more towards the individuals-are-independent side than we are now. But realistically I don’t think this is a good use of our resources because I personally am not sure how to do that, I personally am not interested in singlehandedly inventing the science of shifting position on the individualism spectrum, I don’t think trying to invent this science is a great use of anyone else’s time, and if someone did claim they invented this science, it would take a lot of evidence for me to believe them. 

(again, I think I’m being terribly unfair here to the author, who was genuinely worried about these blindspots, but I’m using this as an example of _my reaction to_ different types of criticism)

What’s the EA equivalent of the s-ketamine critique?

[A Critical Review Of Open Philanthropy’s Bet On Criminal Justice Reform](https://forum.effectivealtruism.org/posts/h2N9qEbvQ6RHABcae/a-critical-review-of-open-philanthropy-s-bet-on-criminal) argues that one of a major EA funder’s programs was substantially less effective than their other programs, that this had been easy to notice for a while, and that despite this they continued the program instead of changing it or cutting their losses (for a while; they did eventually stop).

Everyone in EA is very nice, so all of the responses were phrased as “thank you for this constructive criticism, but having said that I wanted to raise…” But subtracting out the usual niceness level, I get the impression it actually hit a nerve. There was some pretty deep discussion about whether the criticism was fair, whether it was excessively hostile to identifiable individuals, and (of course) nitpicking all the math.

Here are some differences I noticed between the experience of reading the more specific criminal justice criticism vs. the more paradigmatic structures-and-individualism criticism:

  * Before reading the specific criticism, I wouldn’t have been able to predict its conclusion. Was this program more effective than other programs? Less effective? But before reading the paradigmatic criticism, I could predict its conclusion pretty well. “We are all more interconnected than we think” is a typical piece of Profound Wisdom, and nobody ever says the opposite.

  * I can name several people who gain/lose status from the specific criticism, and I expect those people to be upset, push back, or otherwise have strong opinions. I can’t think of anyone like that for the paradigmatic criticism.

  * The specific criticism carries an obvious conclusion: cancel this one program! (in this case it had already been cancelled, so maybe the conclusion is more like reform various processes to make that happen sooner later on). The paradigmatic criticism is less actionable.




This isn’t to say that paradigmatic criticisms are always bad and useless, and specific criticism is always good. 

But the specific claim at the end of Part I above - that the people in power prefer specific to paradigmatic criticism, because it’s less challenging - seems to me the exact opposite of the truth.

**IV.**

But we’ve got to change paradigms sometimes, right? How do we do that without soliciting paradigmatic criticism?

I don’t know, man, I don’t know. [Thomas Kuhn seemed](https://slatestarcodex.com/2019/01/08/book-review-the-structure-of-scientific-revolutions/) to think of paradigm shifts as almost mystical processes. You don’t go in some specific direction carefully signposted “Next Paradigm”. Anomalous information comes in from the blue, someone happens to be in the right place to detect it, everyone agonizes over it for a while, the enigmas pile up higher and higher, and at some point the free energy becomes unbearable and everything does some multi-dimensional conformation shift and now you have a new paradigm.

By the time ordinary outsiders hear about a paradigm shift, it’s already well into its lifecycle. _Then_ it looks like a hidebound establishment refusing to go in the direction marked “Next Paradigm”. This is a fun situation, because _on these rare occasions only_ you can be a bold pioneer who’s infinitely far ahead of the experts just by following signposts. It’s so fun that it can be hard to resist the temptation to believe you’re in it: just as economists have predicted ten of the last two recessions, so science journalists have predicted ten of the last two paradigm shifts. 

These are two different phases: waiting for anomalies and inspiration, vs. yelling at the hidebound establishment to accept the new order. And they require different virtues.

The virtue of the first phase is looking for anomalies. These aren’t vague, sweeping, and ideological. The anomalies with Newtonian gravity weren’t things like “action at a distance doesn’t feel scientific enough” or “it doesn’t sufficiently glorify Jesus Christ” or even “it’s insufficiently elegant”. The one that ended up most important was “its estimate for the precession of the orbit of Mercury is off by forty arc-seconds per century”.

I don’t know if it’s meaningful to talk about EA needing “another paradigm” - this whole discussion conflates scientific theories, ideologies, and methods for producing change. But if it does, it will come from complaints like the criminal justice criticism, which record boring ways that EA-as-it-exists-now made bad decisions on some specific point. If we had a hundred such complaints, maybe we could figure out some broader failure mode and how to deal with it.

The virtue of the second phase is changing your mind and getting on board with the new program. But the new program has to exist first. If you can’t name a specific new program to get on board with, you’re still in the first phase, and you should be meticulously recording the orbit of Mercury instead of making sweeping statements including the word “hidebound”.

What happens if you demand a new paradigm before enough anomalies have built up? If you incentivize people to preach at you, they’ll do that. But they can’t preach the tenets of the new paradigm, because they don’t know it yet. And they can’t preach the implementable tenets of the old paradigm, because you’ve already implemented them. So instead, they’ll preach things the old paradigm says are good, which haven’t been implemented because they’re vague or impossible or not worth the tradeoff against other considerations. Listen too hard, and you’ll go from a precise and efficient implementation of the old paradigm, to a fuzzier implementation that emphasizes trying to do vague, inefficient, or impossible things. This isn’t just a failure mode of EA or psychiatry, it’s a failure mode of whole societies.

Sorry to everyone I had to implicitly attack in order to make this point. I felt like this of all essays needed to be specific and offend nameable people.
