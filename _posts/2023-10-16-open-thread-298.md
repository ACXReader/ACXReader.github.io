---
title: "Open Thread 298"
subtitle: "..."
date: 2023-10-16
likes: 62
author: Scott Alexander
comments: https://www.astralcodexten.com/api/v1/post/137998410/comments?&all_comments=true
image: https://substack-post-media.s3.amazonaws.com/public/images/56da6793-a950-4ad1-8a76-4895515023da_496x341.png
original-url: https://www.astralcodexten.com/p/open-thread-298
---
This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial [subreddit](https://www.reddit.com/r/slatestarcodex/), [Discord](https://discord.gg/RTKtdut), and [bulletin board](https://www.datasecretslox.com/index.php), and [in-person meetups around the world](https://www.lesswrong.com/community?filters%5B0%5D=SSC). 95% of content is free, but for the remaining 5% you can subscribe [here](https://astralcodexten.substack.com/subscribe?). Also:

**1:** Sorry, I [scheduled the Berkeley fall ACX meetup for next Saturday](/p/meetups-everywhere-2023-times-and), but my schedule has changed and I won’t be able to go. Meetups Czar Skyler and lots of other great people will still be there, so have fun without me!

**2:** One of the recent [impact market](/p/impact-market-mini-grants-results) forecasting projects, OPTIC, asks me to broadcast the following appeal:

> [OPTIC](https://www.opticforecasting.com/) is announcing intercollegiate forecasting tournaments in SF, DC, and Boston. Think 1-day hackathon/olympiad/debate tournament, but for forecasting the future — teams predict on topics ranging from geopolitics to celebrity twitter patterns to financial asset prices, and the best forecasters get thousands of dollars in cash prizes and exclusive internships at [Metaculus](http://metaculus.com/).
> 
> Day of, teams give probabilistic predictions for a couple hours on about 30 given questions (with breaks for lunch & speakers). Teams are 3-5 competitors, and we’ll place you on a team if you don’t already have one in mind. A few months after the tournament, all questions resolve and winners are announced/awarded: until then, you can track how your team is doing in real time.
> 
> Tournaments will be run in the Bay Area (November 4), DC (November 18) and Boston (December 2).  _**Register[here](http://bit.ly/opticf23registrationform) (3-7 min)!**_
> 
> You can look over our [previously used questions](https://www.notion.so/Spring-2023-Questions-6b44ec1dca65410086c98151665b1470?pvs=21), check out our [FAQ](https://www.opticforecasting.com/faq) for more details, and always feel free to [reach out](http://opticforecasting.com/contact)!

**3:** Updates on the AI pause debate:

  * Holly Elmore and PauseAI are [holding pro-pause protests October 21 in eight cities](https://pauseai.info/2023-oct) around the world, including San Francisco.

  * Quintin Pope has some good on X, including [a debate with Liron Shapira](https://twitter.com/liron/status/1712301462037094770) and [this explanation of where he parts ways with older AI safety paradigms](https://twitter.com/QuintinPope5/status/1709363036849618983).

  * Evan Hubinger argues that [Responsible Scaling Policies Are Pauses Done Right](https://www.lesswrong.com/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right)

  * The Centre for the Governance of AI has a paper on [Coordinated Pausing: An Evaluation-Based Coordination Scheme for Frontier AI Developers](https://www.governance.ai/research-paper/coordinated-pausing-evaluation-based-scheme)




**4:** Steve Hsu asks me to link his appeal for [why you should support the Study Of Mathematically Precocious Youth](https://infoproc.blogspot.com/2023/10/smpy-65-help-support-smpy-longitudinal.html); go [here](https://vanderbilt.alumniq.com/giving/to/mathematicallyprecociousyouth?appealcode=PGW01) to donate.

**5:** The New York Times recently published [an article about the Manifest prediction market conference](https://archive.ph/L0uGq). I think it’s overall very good, and appreciate the care that the reporter put in to understanding the ideas (plus the frankly majestic picture of the Manifold co-founders). I do want to correct one paragraph, though:

> The Rationalist revival has put wind into the sails of start-ups like Manifold Markets, which was initially funded by a grant program run by Astral Codex Ten, a Rationalist blog that has promoted prediction markets. (It also received $1 million from the FTX Future Fund, the philanthropic arm of the bankrupt crypto exchange whose founder, Sam Bankman-Fried, is a fan of prediction markets.)

I think a natural reading of this sentence is that Astral Codex Ten received $1 million from the FTX Future Fund. Some people who read the article said they understood it this way and thought I took FTX money. I didn’t. The article meant to say that Manifold did. 

I appreciate NYT moving from its previous policy of [blatant and deliberate falsehoods about me](/p/statement-on-new-york-times-article), to a newer, kinder policy of accidental and ambiguous falsehoods about me. That’s the first step towards not publishing any falsehoods about me at all! Still, I want to set the record straight.

A related NYT podcast also discussed Manifest and prediction markets; [see here for partial transcript](https://www.lesswrong.com/posts/ADkyxynJaaykteLRt/prediction-markets-covered-in-the-nyt-podcast-hard-fork).
