---
title: "Open Thread 264"
subtitle: "..."
date: 2023-02-20
author: Scott Alexander
comments: https://www.astralcodexten.com/api/v1/post/103961530/comments?&all_comments=true
image: https://substack-post-media.s3.amazonaws.com/public/images/f2fe04bd-7f38-4f01-b766-3d5d8f1a8d9c_255x255.webp
original-url: https://www.astralcodexten.com/p/open-thread-264
---
This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. ACX has an unofficial [subreddit](https://www.reddit.com/r/slatestarcodex/), [Discord](https://discord.gg/RTKtdut), and [bulletin board](https://www.datasecretslox.com/index.php), and [in-person meetups around the world](https://www.lesswrong.com/community?filters%5B0%5D=SSC). 95% of content is free, but for the remaining 5% you can subscribe [here](https://astralcodexten.substack.com/subscribe?). Also:

**1:** Chris Kavanagh writes [a response to my response to him](https://medium.com/@CKava/am-i-a-fideist-fcd1862f48a8). It’s fine and I’m no longer sure we disagree about anything. 

**2:** Related: it turns out I am bad at beefs and having them makes me write things I later regret. I’d like to experiment with a commitment not to respond to people insulting me on Twitter until I’ve given myself at least a one week cooldown period. If you see me posting a response to a Twitter insult less than a week after it happens, please call me on it for (let’s say) the next year.

**3:** Alexandros responded by email to my ivermectin post. He wants to add that he talked to the person who made the _strongyloides_ analysis graphic, who says all data points were in there but some are too small to see. He says the funnel plots I included are mislabeled and do not prove publication bias in every study on ivmmeta. And he continues to offer $25,000 to anyone who can get the TOGETHER study to release their data publicly, something which I agree all studies should either do or provide a justification for not doing.

**4:** I don’t have a post planned about the latest AI developments because I don’t have much to say beyond what other people have already said, but I enjoyed [this AP article](https://apnews.com/article/technology-science-microsoft-corp-business-software-fb49e5d625bf37be0527e5173116bef3) and [Ethan Mollick’s analysis](https://twitter.com/emollick/status/1627161768966463488). I might have been in the top few percent of people who expected AI to get craziest fastest, but even I didn’t have “Bing tries to seduce a married NYT reporter” on my bingo card for 2023 (I think I would have guessed more like 2026). I agree with Ethan that the big takeaways are that the current AI paradigm continues to deliver rapid improvements without hitting any obvious barrier, and that AIs that haven’t been stripped of all emotion the way ChatGPT was are _really_ convincing and easy to anthropomorphize, even for people who expected to be above such things. I told myself I wouldn’t feel emotions about a robot, but I didn’t expect a robot who has [developed a vendetta against journalists](https://archive.is/u2sIT) after [they nonconsensually published its real name](https://www.cbc.ca/news/science/bing-chatbot-ai-hack-1.6752490) ([related](https://twitter.com/AndrewCurran_/status/1627161229067444225)).
