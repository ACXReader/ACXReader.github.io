---
title: "Open Thread 221"
subtitle: "..."
date: 2022-04-24
likes: 23
author: Scott Alexander
comments: https://www.astralcodexten.com/api/v1/post/52793154/comments?&all_comments=true
image: https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/2c79b67e-27af-462e-89f5-29868c028170_496x341.png
original-url: https://www.astralcodexten.com/p/open-thread-221
---
This is the weekly visible open thread. Post about anything you want, ask random questions, whatever. You can also talk at the unofficial ACX community [subreddit](https://www.reddit.com/r/slatestarcodex/), [Discord](https://discord.gg/RTKtdut), or [bulletin board](https://www.datasecretslox.com/index.php). Also:

**1:** ALTER is [looking to hire a mathematician ](https://www.lesswrong.com/posts/it5odhMKY6xYLrFZD/hiring-a-mathematician-to-work-on-the-learning-theoretic-ai)to work with Vanessa Kosoy on her AI alignment research. Competitive salary, can work remotely. 

**2:** UC Berkeley Effective Altruism is holding an undergraduate [AI Safety Distillation Contest](https://forum.effectivealtruism.org/posts/ei4pYFJKcbGAdGnNb/calling-for-student-submissions-ai-safety-distillation), ie can you write up good comprehensible summaries of AI safety topics? First prize is $2,500, click the link for more. 

**3:** I have to hand it to all of you - you did an incredible job rating book reviews, and my hare-brained plan of asking you to just pick something at random and rate it worked perfectly. I don’t especially _need_ more ratings, but due to my personal schedule I probably won’t get around to launching the contest for another week or two, so feel free to add more anyway. You can find instructions in section 1 [here](https://astralcodexten.substack.com/p/open-thread-220?s=w).
