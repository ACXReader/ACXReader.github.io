---
title: "\"Through A Glass Darkly\" In Asterisk Magazine"
subtitle: "..."
date: 2023-06-26
likes: 70
author: Scott Alexander
comments: https://www.astralcodexten.com/api/v1/post/131243513/comments?&all_comments=true
image: https://substack-post-media.s3.amazonaws.com/public/images/38c0804c-cba9-4346-b039-74848e921fcf_1350x788.png
original-url: https://www.astralcodexten.com/p/through-a-glass-darkly-in-asterisk
---
I have an article summarizing attempts to forecast AI progress, including a five year check-in on the predictions in [Grace et al (2017)](https://slatestarcodex.com/2017/06/08/ssc-journal-club-ai-timelines/). It’s not here, it's at [asteriskmag.com](https://asteriskmag.com), a rationalist / effective altruist magazine: **[Through A Glass Darkly](https://asteriskmag.com/issues/03/through-a-glass-darkly)**. This is their AI issue (it’s not always so AI focused). Other stories include:

  * **[Crash Testing GPT-4](https://asteriskmag.com/issues/03/crash-testing-gpt-4)** : Before releasing GPT-4, OpenAI sent a preliminary version to the Alignment Research Center to test it for unsafe capabilities; the detail that [made the news](https://gizmodo.com/gpt4-open-ai-chatbot-task-rabbit-chatgpt-1850227471) was how the AI managed to hire a gig worker to solve CAPTCHAs for it by pretending to be a blind person. Asterisk interviews Beth Barnes, leader of the team that ran those tests.

  * **[What We Get Wrong About AI And China](https://asteriskmag.com/issues/03/what-we-get-wrong-about-ai-china)** : Professor Jeffrey Ding discusses the Chinese AI situation. If I’m understanding right, China is 1-2 years behind the US, but that this number underplays the size of the gap, and if the US stopped innovating today, China wouldn’t necessarily push ahead in 3 years. Today’s [Marginal Revolution links](https://marginalrevolution.com/marginalrevolution/2023/06/monday-assorted-links-412.html) included [a claim](https://twitter.com/Yampeleg/status/1673112207347920896) that a new Chinese model beats GPT-4; I’m very skeptical and waiting to hear more.

  * **[The Transistor Cliff](https://asteriskmag.com/issues/03/the-transistor-cliff#the-memory-wall)** : Sarah Constantin on the future of microchips. Most predictions about the future of AI center around the idea that lower compute costs → bigger training runs → smarter models. But how sure are we that we can keep decreasing compute costs indefinitely? Will we reach physical limits or memory bottlenecks? What if we do?

  * **[A Debate About AI And Explosive Growth](https://asteriskmag.com/issues/03/the-great-inflection-a-debate-about-ai-and-explosive-growth)** : Tamay Besiroglu vs. Matt Clancy. Will AI be just another invention that is probably good for the economy but leaves GDP trajectories overall unchanged? Or will it create a technoeconomic singularity leading to “impossibly” fast economic growth? A good followup for my recent [Davidson On Takeoff Speeds](https://astralcodexten.substack.com/p/davidson-on-takeoff-speeds). I don’t think they emphasized enough the claim that the _natural_ trajectory of growth had long been trending towards a singularity in the 2020s, [we only started deviating from that natural trajectory since ~1960 or so](https://slatestarcodex.com/2019/04/22/1960-the-year-the-singularity-was-cancelled/), and that we’re just debating whether AI will restore the natural curve rather than whether it will do some bizarre unprecedented thing that we should have a high prior against.




Plus superforecaster Jonathan Mann on [whether AI will take tech jobs](https://asteriskmag.com/issues/03/ai-isn-t-coming-for-tech-jobs-yet), Kelsey Piper on [the different camps within AI safety](https://asteriskmag.com/issues/03/a-field-guide-to-ai-safety), Michael Gordin on [how long until Armageddon](https://asteriskmag.com/issues/03/how-long-until-armageddon) (surprisingly _not_ AI related!), Robert Long on [what the history of debating animal intelligence tells us about AI intelligence](https://asteriskmag.com/issues/03/are-we-smart-enough-to-know-how-smart-ais-are), Avital Balwit on [the technical aspects of regulating AI compute](https://asteriskmag.com/issues/03/how-we-can-regulate-ai), Carl Robichaud on [how we (sort of) succeeded at nuclear non-proliferation](https://asteriskmag.com/issues/03/the-puzzle-of-non-proliferation), and Jamie Wahls’ [short story about chatbot romance](https://asteriskmag.com/issues/03/emotional-intelligence-amplification).

Congratulations again to Clara, Jake, and the rest of the Asterisk team! As always, you can subscribe [here](https://store.asteriskmag.com/).
